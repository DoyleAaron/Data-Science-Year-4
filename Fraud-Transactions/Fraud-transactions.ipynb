{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('Fraud.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just for the basic imports of the model to ensure I am accessing everything correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df.drop(['step', 'nameOrig', 'nameDest'], axis=1)\n",
    "filtered_data.to_csv('filtered_data.csv')\n",
    "X = filtered_data[['amount', 'oldbalanceOrg', 'newbalanceOrig']]\n",
    "Y = filtered_data['isFraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above here, I am dropping rows that I dont believe will have any predictive value as they are just time frames, the account the transaction is from and the account that the transaction is to. \n",
    "\n",
    "I am also assigning X and Y so that I can break up my test and training data in the next cell below me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=258)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code cell I am just splitting my data into an 80% training and a 20% test dataset so that I can accurately test how well the model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the decision tree model is:  0.992319987678032 %\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, class_weight=\"balanced\") # ChatGPT suggested to use n_estimators=50, max_depth=10\n",
    "rf_model.fit(x_train, y_train)\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('The accuracy of the decision tree model is: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code block I am training the model to the data that I specified in the last cell. I ran into some interesting issues on this code block as I was getting an overfit to the data with a 1.00 score for the data. I went researching why this may be and I believe it is because originally I was using a low amount of estimators and I didn't specify a max depth for the decision trees. \n",
    "\n",
    "Once I added class weight = balanced it gave me a better working algorithm because the data is heavily favoured towards not being fraud as this happens way more in the dataset. This was a big contirbutor to the dataset being incorrect and balancing the class weight gave much better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result:\n",
      "Fraud\n"
     ]
    }
   ],
   "source": [
    "example_prediction = pd.DataFrame({'amount': [10000], 'oldbalanceOrg': [10000], 'newbalanceOrig': [0]}) \n",
    "\n",
    "prediction = rf_model.predict(example_prediction)\n",
    "print('Prediction result:')\n",
    "if prediction[0] == 0:\n",
    "    print(\"Not Fraud\")\n",
    "else:\n",
    "    print(\"Fraud\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code block I am using the same method of predictions as I did for my decision tree which allows me to enter sample data for the prediction and have the model display the prediction results based off of that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Setup\n",
    "There is some steps to setting up this dataset if you wish to run this file as the dataset cannot be published to GitHub due to it being over 100mb. \n",
    "\n",
    "1. Download the dataset from this link: https://www.kaggle.com/datasets/kcoder123/fraud-dataset\n",
    "2. Unzip the dataset and you should see Fraud.csv\n",
    "3. Move that into the Fraud-Transactions folder\n",
    "4. Run the Jupyter notebook Fraud-transactions.ipynb\n",
    "\n",
    "# Data Overview\n",
    "This dataset was obtained from here (https://www.kaggle.com/datasets/kcoder123/fraud-dataset). This is a kaggle dataset that outlines some details from a bank users account. These details are going to be used to help predict whether or not a transaction from a users account is a fraudulent transaction or not. I chose this dataset as I thought it would be an interseting dataset to use as I wanted to see what factors would be key in predicting fraudulent transactions and it could be useful for users to see if they think there is a fraudulent transaction on their account\n",
    "\n",
    "# Pre Processing\n",
    "There was some pre-processing for this dataset. This is quite a big dataset so I knew that I would have to try and cut a lot of the data from it if it wasnt absolutely necessary. The first thing I did was import it using Pandas and then I began to remove the fields that I didn't think would be useful for making a prediction. For this I chose to remove step as it is just a time period which I didn;t feel had any predictive qualities and then I also removed the account ID that the transaction was going to and from as these are just identifiers and for this model don't provide any use for predictions. Then I split the remaining data into an 80% training block and left another 20% to test the model once it was trained.\n",
    "\n",
    "# Data Understanding\n",
    "I feel like I now have a good understanding of my dataset as I have done a lot of pre-proccesing on the data. I also did some research into transactions and what each of the headings fully meant as it was an area that I didn't have too much knowledge in before. The values that ended up having an effect on the prediction the most were the value that was being transferred, the account balance before and the account balance after. This makes sense as if an account is being completely or mostly drained it is most likely going to be a fraudulent transaction but it was interesting to find out this information as I wasn't sure what would've been necessary beforehand.\n",
    "\n",
    "# Algorithm\n",
    "For this model I implemented a random forest model using Sci-Kit Learn's random forest model, I used this model as its a binary result for my data and random forests work well for binary classification. This model has a 99% accuracy rating which for any model is a very good rating. I orignally had a 100% rating but this indicated to me that the model was overfitting to the data so I had to add a set amount of classifiers and class weight, this helped as the dataset is a vast majority of non fraudulent transactions so adding this allowed the model not to predict every value as not being fraudulent due to the sheer amount of them it was trained on.\n",
    "\n",
    "# Technologies Used\n",
    "I used a few different technologies whilst creating this model such as Pandas which allowed me to read in my dataset and then I used a few of Sci-Kit Learn's tools to build my random forest model such as their accuracy score and their train and test split and their random forest model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
